{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Proyecto Final - DAFT10 - Henry*\n",
    "Spirit Liquors - El capital Oculto\n",
    "\n",
    "            Grupo 02: \n",
    "                 Angela Gaviria\n",
    "                 Diego Diaz\n",
    "                 Germ√°n Presa\n",
    "                 Gonzalo Aguirre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0- Configuraci√≥n del entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Intalaci√≥n de Librerias a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: wrangler in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.1.8.6)\n",
      "Requirement already satisfied: datetime in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.5)\n",
      "Requirement already satisfied: geopandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (2.3.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: markdown in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (3.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (3.1.5)\n",
      "Collecting argparse (from wrangler)\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: docutils in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (0.21.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (6.0.2)\n",
      "Requirement already satisfied: watchdog in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (6.0.0)\n",
      "Requirement already satisfied: blinker in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from wrangler) (1.9.0)\n",
      "Requirement already satisfied: zope.interface in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from datetime) (7.2)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopandas) (0.10.0)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopandas) (3.7.0)\n",
      "Requirement already satisfied: shapely>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopandas) (2.0.7)\n",
      "Requirement already satisfied: webencodings in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->wrangler) (3.0.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kaggle) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->kaggle) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->kaggle) (0.4.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from zope.interface->datetime) (75.8.0)\n",
      "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalo librerias para el caso que no esten\n",
    " \n",
    "%pip install kaggle pandas numpy matplotlib seaborn wrangler datetime geopandas pyodbc sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista todas las librer√≠as y versiones instaladas en tu entorno de Python, y las guardo en un .txt para el momento de compartirlas\n",
    "\n",
    "! pip freeze > requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Importaci√≥n de Librerias a utilizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias \n",
    "\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "from matplotlib.dates import DateFormatter # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Descarga de DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/bhanupratapbiswas/inventory-analysis-case-study\n",
      "Descarga iniciada...\n",
      "Esperando a que el archivo ZIP aparezca en la carpeta...\n",
      "Archivo ZIP encontrado: C:\\Users\\diald\\OneDrive\\Diego\\SoyHENRY\\PF\\DATASETDescarga\\inventory-analysis-case-study.zip\n",
      "Descarga finalizada correctamente.\n",
      "Archivo descomprimido exitosamente.\n",
      "Archivo ZIP eliminado.\n",
      "Registro de descarga actualizado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import zipfile  # Para manejar archivos ZIP\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuraci√≥n del archivo de autenticaci√≥n de Kaggle\n",
    "kaggle_json_path = r\"C:\\Users\\Lenovo\\.kaggle\\kaggle.json\"\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.dirname(kaggle_json_path)\n",
    "\n",
    "# Inicializar la API de Kaggle\n",
    "try:\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "except Exception as e:\n",
    "    print(f\"Error en la autenticaci√≥n de Kaggle: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Dataset que queremos descargar\n",
    "dataset = \"bhanupratapbiswas/inventory-analysis-case-study\"\n",
    "\n",
    "# Directorio de salida\n",
    "output_path = r\"C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Archivo de registro para la √∫ltima descarga\n",
    "log_file_path = os.path.join(output_path, \"last_download.log\")\n",
    "\n",
    "# Eliminar archivos ZIP previos en la carpeta\n",
    "zip_files = [f for f in os.listdir(output_path) if f.endswith('.zip')]\n",
    "for zip_file in zip_files:\n",
    "    try:\n",
    "        os.remove(os.path.join(output_path, zip_file))\n",
    "    except Exception as e:\n",
    "        print(f\"Error al eliminar archivo previo {zip_file}: {e}\")\n",
    "\n",
    "# Descargar el dataset\n",
    "print(\"Descargando dataset...\")\n",
    "try:\n",
    "    api.dataset_download_files(dataset, path=output_path, unzip=False)\n",
    "    print(\"Descarga iniciada...\")\n",
    "except Exception as e:\n",
    "    print(f\"Error en la descarga: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Esperar hasta que el archivo aparezca en la carpeta\n",
    "timeout = 30  # Tiempo m√°ximo de espera en segundos\n",
    "elapsed_time = 0\n",
    "zip_file_path = None  # Inicializar la variable antes del bucle\n",
    "\n",
    "print(\"Esperando a que el archivo ZIP aparezca en la carpeta...\")\n",
    "\n",
    "while elapsed_time < timeout:\n",
    "    zip_files = [f for f in os.listdir(output_path) if f.endswith('.zip')]\n",
    "    if zip_files:\n",
    "        zip_file_path = os.path.join(output_path, zip_files[0])  # Tomar el primer archivo ZIP encontrado\n",
    "        print(f\"Archivo ZIP encontrado: {zip_file_path}\")\n",
    "        break  # Salir del bucle si se encuentra el archivo\n",
    "    time.sleep(2)  # Esperar 2 segundos antes de volver a verificar\n",
    "    elapsed_time += 2\n",
    "\n",
    "# Verificar si realmente se encontr√≥ el archivo ZIP\n",
    "if zip_file_path is None or not os.path.exists(zip_file_path):\n",
    "    print(f\"Error: No se encontr√≥ ning√∫n archivo ZIP despu√©s de {timeout} segundos.\")\n",
    "    exit(1)\n",
    "\n",
    "# Esperar a que la descarga finalice completamente (verificando el tama√±o del archivo)\n",
    "previous_size = -1\n",
    "while True:\n",
    "    current_size = os.path.getsize(zip_file_path)\n",
    "    if current_size == previous_size:  # Si el tama√±o no cambia en 4 segundos, la descarga termin√≥\n",
    "        print(\"Descarga finalizada correctamente.\")\n",
    "        break\n",
    "    previous_size = current_size\n",
    "    time.sleep(4)\n",
    "\n",
    "# Descomprimir el archivo ZIP\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_path)\n",
    "        print(\"Archivo descomprimido exitosamente.\")\n",
    "\n",
    "    # Eliminar el archivo ZIP despu√©s de extraerlo\n",
    "    os.remove(zip_file_path)\n",
    "    print(\"Archivo ZIP eliminado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al descomprimir el archivo: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Guardar el timestamp de la descarga en un archivo de log\n",
    "try:\n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"√öltima descarga: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    print(\"Registro de descarga actualizado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al escribir en el archivo de log: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el archivo CSV\n",
    "df_productos = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\2017PurchasePricesDec.csv', index_col=None)\n",
    "df_inv_inicial = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\BegInvFINAL12312016.csv', index_col=None)\n",
    "df_inv_final = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\EndInvFINAL12312016.csv', index_col=None)\n",
    "df_proveedores = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\InvoicePurchases12312016.csv', index_col=None)\n",
    "df_compras = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\PurchasesFINAL12312016.csv', index_col=None)\n",
    "df_ventas = pd.read_csv(r'C:\\Users\\Lenovo\\Documents\\henry da-ft10\\Proyecto Final\\DataSet\\SalesFINAL12312016.csv', index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Conexi√≥n de Python a SQL Server en Cluod SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Conexi√≥n exitosa a Cloud SQL\n"
     ]
    }
   ],
   "source": [
    "# Conectar Python a SQL Server en Cloud SQL\n",
    "\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Configuraci√≥n de conexi√≥n a SQL Server en Cloud SQL\n",
    "DB_HOST = \"34.176.175.250\"\n",
    "DB_NAME = \"SpiritLiquor\"\n",
    "DB_USER = \"sqlserver\"\n",
    "DB_PASSWORD = \"proyectofinal\"\n",
    "\n",
    "# Cadena de conexi√≥n con ODBC\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={DB_HOST};DATABASE={DB_NAME};UID={DB_USER};PWD={DB_PASSWORD}\"\n",
    "\n",
    "# Crear conexi√≥n con pyodbc\n",
    "try:\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    print(\" Conexi√≥n exitosa a Cloud SQL\")\n",
    "except Exception as e:\n",
    "    print(f\" Error en la conexi√≥n: {e}\")\n",
    "\n",
    "# Conexi√≥n con SQLAlchemy para manipulaci√≥n de datos\n",
    "engine = create_engine(f\"mssql+pyodbc://{DB_USER}:{DB_PASSWORD}@{DB_HOST}/{DB_NAME}?driver=ODBC+Driver+17+for+SQL+Server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *1- Creaci√≥n de Base de Datos y Tablas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creaci√≥n de la Base de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Base de datos 'SpiritLiquor' creada exitosamente o ya exist√≠a.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Crear la base de datos en caso de que no exista\n",
    "\n",
    "# Configuraci√≥n de conexi√≥n (sin base de datos espec√≠fica)\n",
    "DB_HOST = \"34.176.175.250\"\n",
    "DB_PORT = \"1433\"\n",
    "DB_USER = \"sqlserver\"\n",
    "DB_PASSWORD = \"proyectofinal\"\n",
    "\n",
    "# Conexi√≥n al servidor sin especificar la base de datos\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={DB_HOST},{DB_PORT};UID={DB_USER};PWD={DB_PASSWORD}\"\n",
    "\n",
    "try:\n",
    "    # Conectar al servidor de SQL Server\n",
    "    conn = pyodbc.connect(conn_str, autocommit=True)  # üîπ Activar autocommit para evitar la transacci√≥n\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Crear la base de datos solo si no existe\n",
    "    cursor.execute(\"IF NOT EXISTS (SELECT * FROM sys.databases WHERE name = 'SpiritLiquor') CREATE DATABASE SpiritLiquor;\")\n",
    "    \n",
    "    print(\"‚úÖ Base de datos 'SpiritLiquor' creada exitosamente o ya exist√≠a.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error al crear la base de datos: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creaci√≥n de Tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tablas creadas exitosamente en SQL Server.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Configuraci√≥n de conexi√≥n a SQL Server en Cloud SQL\n",
    "DB_HOST = \"34.176.175.250\"  # Reemplaza con la IP de tu instancia en GCP\n",
    "DB_NAME = \"SpiritLiquor\"  # Nombre de tu base de datos\n",
    "DB_USER = \"sqlserver\"\n",
    "DB_PASSWORD = \"proyectofinal\"\n",
    "\n",
    "# Cadena de conexi√≥n ODBC\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={DB_HOST};DATABASE={DB_NAME};UID={DB_USER};PWD={DB_PASSWORD}\"\n",
    "\n",
    "# Script SQL para crear las tablas\n",
    "sql_script = \"\"\"\n",
    "-- Tabla de tiendas\n",
    "CREATE TABLE dim_store (\n",
    "    id_store INT PRIMARY KEY NOT NULL,\n",
    "    city VARCHAR(100)\n",
    ");\n",
    "\n",
    "-- Tabla de proveedores\n",
    "CREATE TABLE dim_vendors (\n",
    "    id_vendors_number INT PRIMARY KEY NOT NULL,\n",
    "    vendors_name VARCHAR(100) UNIQUE\n",
    ");\n",
    "\n",
    "-- Tabla de productos\n",
    "CREATE TABLE dim_products (\n",
    "    id_brand INT PRIMARY KEY NOT NULL,\n",
    "    description VARCHAR(100),\n",
    "    size VARCHAR(100),\n",
    "    volume DECIMAL(15, 2),\n",
    "    purchase_price DECIMAL(15, 2),\n",
    "    sales_price DECIMAL(15, 2),\n",
    "    classification INT,\n",
    "    id_vendors_number INT,\n",
    "    FOREIGN KEY (id_vendors_number) REFERENCES dim_vendors(id_vendors_number)\n",
    ");\n",
    "\n",
    "-- Tabla de facturas de compra\n",
    "CREATE TABLE dim_invoice_purchase (\n",
    "    id_po_number INT PRIMARY KEY NOT NULL,\n",
    "    id_vendors_number INT,\n",
    "    po_date DATE,\n",
    "    pay_date DATE,\n",
    "    total_quantity INT,\n",
    "    total_amount DECIMAL(15, 2),\n",
    "    freight DECIMAL(15, 2),\n",
    "    approval VARCHAR(100),\n",
    "    FOREIGN KEY (id_vendors_number) REFERENCES dim_vendors(id_vendors_number)\n",
    ");\n",
    "\n",
    "-- Tabla de inventario\n",
    "CREATE TABLE facts_inventario (\n",
    "    id_inventario INT PRIMARY KEY NOT NULL IDENTITY(1,1),\n",
    "    id_store INT,\n",
    "    id_brand INT,\n",
    "    on_hands INT CHECK (on_hands >= 0),\n",
    "    sales_price DECIMAL(15, 2),\n",
    "    dates DATE DEFAULT GETDATE(),\n",
    "    id_purchases INT,\n",
    "    id_sales INT,\n",
    "    FOREIGN KEY (id_store) REFERENCES dim_store(id_store),\n",
    "    FOREIGN KEY (id_brand) REFERENCES dim_products(id_brand)\n",
    ");\n",
    "\n",
    "-- Tabla de ventas\n",
    "CREATE TABLE sales (\n",
    "    id_sales INT PRIMARY KEY NOT NULL IDENTITY(1,1),\n",
    "    id_inventario INT,\n",
    "    id_store INT,\n",
    "    id_vendors_number INT,\n",
    "    id_brand INT,\n",
    "    sales_date DATE,\n",
    "    quantity_sales INT,\n",
    "    sales_price DECIMAL(15, 2),\n",
    "    total_amount DECIMAL(15, 2),\n",
    "    excise_tax DECIMAL(15, 2),\n",
    "    FOREIGN KEY (id_inventario) REFERENCES facts_inventario(id_inventario),\n",
    "    FOREIGN KEY (id_store) REFERENCES dim_store(id_store),\n",
    "    FOREIGN KEY (id_vendors_number) REFERENCES dim_vendors(id_vendors_number),\n",
    "    FOREIGN KEY (id_brand) REFERENCES dim_products(id_brand)\n",
    ");\n",
    "\n",
    "-- Tabla de compras\n",
    "CREATE TABLE purchase (\n",
    "    id_purchases INT PRIMARY KEY NOT NULL IDENTITY(1,1),\n",
    "    id_inventario INT,\n",
    "    id_store INT,\n",
    "    id_brand INT,\n",
    "    id_vendor_number INT,\n",
    "    id_po_number INT,\n",
    "    receiving_date DATE,\n",
    "    purchase_price DECIMAL(15, 2),\n",
    "    quantity_purchases INT,\n",
    "    total_price DECIMAL(15, 2),\n",
    "    FOREIGN KEY (id_inventario) REFERENCES facts_inventario(id_inventario),\n",
    "    FOREIGN KEY (id_store) REFERENCES dim_store(id_store),\n",
    "    FOREIGN KEY (id_brand) REFERENCES dim_products(id_brand),\n",
    "    FOREIGN KEY (id_vendor_number) REFERENCES dim_vendors(id_vendors_number)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    # Conectar a la base de datos\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Ejecutar el script SQL para crear las tablas\n",
    "    cursor.execute(sql_script)\n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Tablas creadas exitosamente en SQL Server.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al crear las tablas: {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *2- Limpieza preliminar*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Tabla a analizar 2017PuchasePricesDec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_pur = pd.read_csv('2017PurchasePricesDec.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand               int64\n",
      "Description        object\n",
      "Price             float64\n",
      "Size               object\n",
      "Volume             object\n",
      "Classification      int64\n",
      "PurchasePrice     float64\n",
      "VendorNumber        int64\n",
      "VendorName         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verificamos tipo de datos\n",
    "print(df_pur.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (12261, 9)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_pur.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brand                  Description  Price   Size Volume  Classification  \\\n",
      "0     58  Gekkeikan Black & Gold Sake  12.99  750mL    750               1   \n",
      "1     62     Herradura Silver Tequila  36.99  750mL    750               1   \n",
      "2     63   Herradura Reposado Tequila  38.99  750mL    750               1   \n",
      "3     72         No. 3 London Dry Gin  34.99  750mL    750               1   \n",
      "4     75    Three Olives Tomato Vodka  14.99  750mL    750               1   \n",
      "\n",
      "   PurchasePrice  VendorNumber                   VendorName  \n",
      "0           9.28          8320  SHAW ROSS INT L IMP LTD      \n",
      "1          28.67          1128  BROWN-FORMAN CORP            \n",
      "2          30.46          1128  BROWN-FORMAN CORP            \n",
      "3          26.11          9165  ULTRA BEVERAGE COMPANY LLP   \n",
      "4          10.94          7245  PROXIMO SPIRITS INC.         \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_pur.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12261 entries, 0 to 12260\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Brand           12261 non-null  int64  \n",
      " 1   Description     12260 non-null  object \n",
      " 2   Price           12261 non-null  float64\n",
      " 3   Size            12260 non-null  object \n",
      " 4   Volume          12260 non-null  object \n",
      " 5   Classification  12261 non-null  int64  \n",
      " 6   PurchasePrice   12261 non-null  float64\n",
      " 7   VendorNumber    12261 non-null  int64  \n",
      " 8   VendorName      12261 non-null  object \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 862.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_pur.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Brand     Price  Classification  PurchasePrice  VendorNumber\n",
      "count 12,261.00 12,261.00       12,261.00      12,261.00     12,261.00\n",
      "mean  17,989.07     38.64            1.71          26.49     10,814.86\n",
      "std   12,528.50    206.15            0.45         156.18     19,007.68\n",
      "min       58.00      0.00            1.00           0.00          2.00\n",
      "25%    5,990.00     10.99            1.00           6.89      3,960.00\n",
      "50%   18,788.00     15.99            2.00          10.65      7,153.00\n",
      "75%   25,117.00     29.99            2.00          20.13      9,552.00\n",
      "max   90,631.00 13,999.90            2.00      11,111.03    173,357.00\n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_pur.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Cantidad NaN  Porcentaje NaN (%)\n",
      "Description             1                0.01\n",
      "Size                    1                0.01\n",
      "Volume                  1                0.01\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "pur_nan = df_pur.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "pur_porcentaje_nan = (pur_nan / len(df_pur)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "pur_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': pur_nan,\n",
    "    'Porcentaje NaN (%)': pur_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "pur_nan_info = pur_nan_info[pur_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(pur_nan_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se puede observar que es una tabla de articulos, por lo cual en la limpieza los valores nulos se dejaran como indefinidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Limpieza de Datos - Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar valores nulos\n",
    "df_pur['Description'] = df_pur['Description'].fillna('undefined')\n",
    "df_pur['Size'] = df_pur['Size'].fillna('undefined')\n",
    "df_pur['Volume'] = df_pur['Volume'].fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos despu√©s de la limpieza:\n",
      " Brand             0\n",
      "Description       0\n",
      "Price             0\n",
      "Size              0\n",
      "Volume            0\n",
      "Classification    0\n",
      "PurchasePrice     0\n",
      "VendorNumber      0\n",
      "VendorName        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de la cantidad de valores nulos en cada columna\n",
    "\n",
    "print(\"Valores nulos despu√©s de la limpieza:\\n\", df_pur.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica la inexistencia de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo los campos necesarios y renombrarlos seg√∫n el formato de la imagen\n",
    "df_dim_products = df_pur.rename(columns={\n",
    "    'Brand': 'ID_Brand',\n",
    "    'Description': 'Description',\n",
    "    'Size': 'Size',\n",
    "    'Volume': 'Volume',\n",
    "    'Price': 'Price',\n",
    "    'PurchasePrice': 'PurchasePrice',\n",
    "    'Classification': 'Classification',\n",
    "    'VendorNumber': 'id_vendor_number'\n",
    "})[['ID_Brand', 'Description', 'Size','Volume' , 'Price', 'PurchasePrice', 'Classification', 'id_vendor_number']]\n",
    "\n",
    "df_dim_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en '2017PurchasePricesDec_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_pur.to_csv('2017PurchasePricesDec_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en '2017PurchasePricesDec_limp.csv'.\")\n",
    "\n",
    "# Guardar los datos filtrados y renombrados en un archivo CSV (se utilizar√° para el posterior llenado)\n",
    "\n",
    "df_dim_products.to_csv('dim_products.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'dim_products.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Tabla a analizar InvoicePurchases12312016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_ip = pd.read_csv('InvoicePurchases12312016.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorNumber      int64\n",
      "VendorName       object\n",
      "InvoiceDate      object\n",
      "PONumber          int64\n",
      "PODate           object\n",
      "PayDate          object\n",
      "Quantity          int64\n",
      "Dollars         float64\n",
      "Freight         float64\n",
      "Approval         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verificamos tipo de datos\n",
    "print(df_ip.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorNumber             int64\n",
      "VendorName              object\n",
      "InvoiceDate     datetime64[ns]\n",
      "PONumber                 int64\n",
      "PODate          datetime64[ns]\n",
      "PayDate         datetime64[ns]\n",
      "Quantity                 int64\n",
      "Dollars                float64\n",
      "Freight                float64\n",
      "Approval                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte datos con fecha en fecha\n",
    "df_ip['InvoiceDate'] = pd.to_datetime(df_ip['InvoiceDate'])\n",
    "df_ip['PODate'] = pd.to_datetime(df_ip['PODate'])\n",
    "df_ip['PayDate'] = pd.to_datetime(df_ip['PayDate'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_ip.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (5543, 10)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_ip.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorNumber                   VendorName InvoiceDate  PONumber     PODate  \\\n",
      "0           105  ALTAMAR BRANDS LLC           2016-01-04      8124 2015-12-21   \n",
      "1          4466  AMERICAN VINTAGE BEVERAGE    2016-01-07      8137 2015-12-22   \n",
      "2           388  ATLANTIC IMPORTING COMPANY   2016-01-09      8169 2015-12-24   \n",
      "3           480  BACARDI USA INC              2016-01-12      8106 2015-12-20   \n",
      "4           516  BANFI PRODUCTS CORP          2016-01-07      8170 2015-12-24   \n",
      "\n",
      "     PayDate  Quantity    Dollars  Freight Approval  \n",
      "0 2016-02-16         6     214.26     3.47      NaN  \n",
      "1 2016-02-21        15     140.55     8.57      NaN  \n",
      "2 2016-02-16         5     106.60     4.61      NaN  \n",
      "3 2016-02-05     10100 137,483.78 2,935.20      NaN  \n",
      "4 2016-02-12      1935  15,527.25   429.20      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_ip.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5543 entries, 0 to 5542\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   VendorNumber  5543 non-null   int64         \n",
      " 1   VendorName    5543 non-null   object        \n",
      " 2   InvoiceDate   5543 non-null   datetime64[ns]\n",
      " 3   PONumber      5543 non-null   int64         \n",
      " 4   PODate        5543 non-null   datetime64[ns]\n",
      " 5   PayDate       5543 non-null   datetime64[ns]\n",
      " 6   Quantity      5543 non-null   int64         \n",
      " 7   Dollars       5543 non-null   float64       \n",
      " 8   Freight       5543 non-null   float64       \n",
      " 9   Approval      374 non-null    object        \n",
      "dtypes: datetime64[ns](3), float64(2), int64(3), object(2)\n",
      "memory usage: 433.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_ip.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       VendorNumber                    InvoiceDate  PONumber  \\\n",
      "count      5,543.00                           5543  5,543.00   \n",
      "mean      20,662.75  2016-07-10 18:59:25.578206720 10,889.42   \n",
      "min            2.00            2016-01-04 00:00:00  8,106.00   \n",
      "25%        3,089.00            2016-04-11 00:00:00  9,503.50   \n",
      "50%        7,240.00            2016-07-11 00:00:00 10,890.00   \n",
      "75%       10,754.00            2016-10-09 00:00:00 12,275.50   \n",
      "max      201,359.00            2017-01-10 00:00:00 13,661.00   \n",
      "std       34,582.16                            NaN  1,600.86   \n",
      "\n",
      "                              PODate                     PayDate   Quantity  \\\n",
      "count                           5543                        5543   5,543.00   \n",
      "mean   2016-06-24 08:48:08.832762112  2016-08-15 06:14:05.607072   6,058.88   \n",
      "min              2015-12-20 00:00:00         2016-02-04 00:00:00       1.00   \n",
      "25%              2016-03-24 12:00:00         2016-05-16 00:00:00      83.00   \n",
      "50%              2016-06-25 00:00:00         2016-08-15 00:00:00     423.00   \n",
      "75%              2016-09-23 00:00:00         2016-11-14 00:00:00   5,100.50   \n",
      "max              2016-12-23 00:00:00         2017-02-19 00:00:00 141,660.00   \n",
      "std                              NaN                         NaN  14,453.34   \n",
      "\n",
      "           Dollars  Freight  \n",
      "count     5,543.00 5,543.00  \n",
      "mean     58,073.38   295.95  \n",
      "min           4.14     0.02  \n",
      "25%         967.81     5.02  \n",
      "50%       4,765.45    24.73  \n",
      "75%      44,587.18   229.66  \n",
      "max   1,660,435.88 8,468.22  \n",
      "std     140,234.03   713.59  \n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_ip.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Verificaci√≥n de nulos por dato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Cantidad NaN  Porcentaje NaN (%)\n",
      "Approval          5169               93.25\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "ip_nan = df_ip.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "ip_porcentaje_nan = (ip_nan / len(df_ip)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "ip_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': ip_nan,\n",
    "    'Porcentaje NaN (%)': ip_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "ip_nan_info = ip_nan_info[ip_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(ip_nan_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorNumber</th>\n",
       "      <th>VendorName</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>PONumber</th>\n",
       "      <th>PODate</th>\n",
       "      <th>PayDate</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Freight</th>\n",
       "      <th>Approval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>ALTAMAR BRANDS LLC</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>8124</td>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>6</td>\n",
       "      <td>214.26</td>\n",
       "      <td>3.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4466</td>\n",
       "      <td>AMERICAN VINTAGE BEVERAGE</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>8137</td>\n",
       "      <td>2015-12-22</td>\n",
       "      <td>2016-02-21</td>\n",
       "      <td>15</td>\n",
       "      <td>140.55</td>\n",
       "      <td>8.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>388</td>\n",
       "      <td>ATLANTIC IMPORTING COMPANY</td>\n",
       "      <td>2016-01-09</td>\n",
       "      <td>8169</td>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>5</td>\n",
       "      <td>106.60</td>\n",
       "      <td>4.61</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>480</td>\n",
       "      <td>BACARDI USA INC</td>\n",
       "      <td>2016-01-12</td>\n",
       "      <td>8106</td>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>2016-02-05</td>\n",
       "      <td>10100</td>\n",
       "      <td>137,483.78</td>\n",
       "      <td>2,935.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>BANFI PRODUCTS CORP</td>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>8170</td>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>2016-02-12</td>\n",
       "      <td>1935</td>\n",
       "      <td>15,527.25</td>\n",
       "      <td>429.20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>9622</td>\n",
       "      <td>WEIN BAUER INC</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>13626</td>\n",
       "      <td>2016-12-21</td>\n",
       "      <td>2017-02-10</td>\n",
       "      <td>90</td>\n",
       "      <td>1,563.00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5539</th>\n",
       "      <td>9625</td>\n",
       "      <td>WESTERN SPIRITS BEVERAGE CO</td>\n",
       "      <td>2017-01-10</td>\n",
       "      <td>13661</td>\n",
       "      <td>2016-12-23</td>\n",
       "      <td>2017-02-18</td>\n",
       "      <td>4617</td>\n",
       "      <td>37,300.48</td>\n",
       "      <td>186.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>3664</td>\n",
       "      <td>WILLIAM GRANT &amp; SONS INC</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>13643</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>2017-02-04</td>\n",
       "      <td>9848</td>\n",
       "      <td>202,815.78</td>\n",
       "      <td>932.95</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541</th>\n",
       "      <td>9815</td>\n",
       "      <td>WINE GROUP INC</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>13602</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>2017-02-08</td>\n",
       "      <td>24747</td>\n",
       "      <td>149,007.56</td>\n",
       "      <td>819.54</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>90058</td>\n",
       "      <td>ZORVINO VINEYARDS</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>13574</td>\n",
       "      <td>2016-12-18</td>\n",
       "      <td>2017-02-12</td>\n",
       "      <td>437</td>\n",
       "      <td>3,608.11</td>\n",
       "      <td>16.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5543 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      VendorNumber                   VendorName InvoiceDate  PONumber  \\\n",
       "0              105  ALTAMAR BRANDS LLC           2016-01-04      8124   \n",
       "1             4466  AMERICAN VINTAGE BEVERAGE    2016-01-07      8137   \n",
       "2              388  ATLANTIC IMPORTING COMPANY   2016-01-09      8169   \n",
       "3              480  BACARDI USA INC              2016-01-12      8106   \n",
       "4              516  BANFI PRODUCTS CORP          2016-01-07      8170   \n",
       "...            ...                          ...         ...       ...   \n",
       "5538          9622  WEIN BAUER INC               2017-01-06     13626   \n",
       "5539          9625  WESTERN SPIRITS BEVERAGE CO  2017-01-10     13661   \n",
       "5540          3664  WILLIAM GRANT & SONS INC     2017-01-02     13643   \n",
       "5541          9815  WINE GROUP INC               2017-01-03     13602   \n",
       "5542         90058  ZORVINO VINEYARDS            2017-01-05     13574   \n",
       "\n",
       "         PODate    PayDate  Quantity    Dollars  Freight Approval  \n",
       "0    2015-12-21 2016-02-16         6     214.26     3.47      NaN  \n",
       "1    2015-12-22 2016-02-21        15     140.55     8.57      NaN  \n",
       "2    2015-12-24 2016-02-16         5     106.60     4.61      NaN  \n",
       "3    2015-12-20 2016-02-05     10100 137,483.78 2,935.20      NaN  \n",
       "4    2015-12-24 2016-02-12      1935  15,527.25   429.20      NaN  \n",
       "...         ...        ...       ...        ...      ...      ...  \n",
       "5538 2016-12-21 2017-02-10        90   1,563.00     8.60      NaN  \n",
       "5539 2016-12-23 2017-02-18      4617  37,300.48   186.50      NaN  \n",
       "5540 2016-12-22 2017-02-04      9848 202,815.78   932.95      NaN  \n",
       "5541 2016-12-20 2017-02-08     24747 149,007.56   819.54      NaN  \n",
       "5542 2016-12-18 2017-02-12       437   3,608.11    16.60      NaN  \n",
       "\n",
       "[5543 rows x 10 columns]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se detectan nulos, la columna approval hace referencia al encargado de dar la aprobaci√≥n a la compra, no es relevante y se rellenara con indefinido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Limpieza de Datos - Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiar valores nulos\n",
    "df_ip['Approval'] = df_ip['Approval'].fillna('undefined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos despu√©s de la limpieza:\n",
      " VendorNumber    0\n",
      "VendorName      0\n",
      "InvoiceDate     0\n",
      "PONumber        0\n",
      "PODate          0\n",
      "PayDate         0\n",
      "Quantity        0\n",
      "Dollars         0\n",
      "Freight         0\n",
      "Approval        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de la cantidad de valores nulos en cada columna\n",
    "\n",
    "print(\"Valores nulos despu√©s de la limpieza:\\n\", df_ip.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en 'InvoicePurchases12312016_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_ip.to_csv('InvoicePurchases12312016_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'InvoicePurchases12312016_limp.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Tabla a analizar BegInvFINAL12312016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_bif = pd.read_csv('BegInvFINAL12312016.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId     object\n",
      "Store            int64\n",
      "City            object\n",
      "Brand            int64\n",
      "Description     object\n",
      "Size            object\n",
      "onHand           int64\n",
      "Price          float64\n",
      "startDate       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verificamos tipo de datos\n",
    "print(df_bif.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se incorpora a startDate el tipo de dato fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId            object\n",
      "Store                   int64\n",
      "City                   object\n",
      "Brand                   int64\n",
      "Description            object\n",
      "Size                   object\n",
      "onHand                  int64\n",
      "Price                 float64\n",
      "startDate      datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte startDate en fecha\n",
    "df_bif['startDate'] = pd.to_datetime(df_bif['startDate'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_bif.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (206529, 9)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_bif.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         InventoryId  Store          City  Brand                  Description  \\\n",
      "0  1_HARDERSFIELD_58      1  HARDERSFIELD     58  Gekkeikan Black & Gold Sake   \n",
      "1  1_HARDERSFIELD_60      1  HARDERSFIELD     60       Canadian Club 1858 VAP   \n",
      "2  1_HARDERSFIELD_62      1  HARDERSFIELD     62     Herradura Silver Tequila   \n",
      "3  1_HARDERSFIELD_63      1  HARDERSFIELD     63   Herradura Reposado Tequila   \n",
      "4  1_HARDERSFIELD_72      1  HARDERSFIELD     72         No. 3 London Dry Gin   \n",
      "\n",
      "    Size  onHand  Price  startDate  \n",
      "0  750mL       8  12.99 2016-01-01  \n",
      "1  750mL       7  10.99 2016-01-01  \n",
      "2  750mL       6  36.99 2016-01-01  \n",
      "3  750mL       3  38.99 2016-01-01  \n",
      "4  750mL       6  34.99 2016-01-01  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_bif.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206529 entries, 0 to 206528\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InventoryId  206529 non-null  object        \n",
      " 1   Store        206529 non-null  int64         \n",
      " 2   City         206529 non-null  object        \n",
      " 3   Brand        206529 non-null  int64         \n",
      " 4   Description  206529 non-null  object        \n",
      " 5   Size         206529 non-null  object        \n",
      " 6   onHand       206529 non-null  int64         \n",
      " 7   Price        206529 non-null  float64       \n",
      " 8   startDate    206529 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(4)\n",
      "memory usage: 14.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_bif.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Store      Brand     onHand      Price            startDate\n",
      "count 206,529.00 206,529.00 206,529.00 206,529.00               206529\n",
      "mean       42.12  13,761.48      20.43      22.25  2016-01-01 00:00:00\n",
      "min         1.00      58.00       0.00       0.00  2016-01-01 00:00:00\n",
      "25%        22.00   3,746.00       7.00       9.99  2016-01-01 00:00:00\n",
      "50%        42.00   8,010.00      12.00      14.99  2016-01-01 00:00:00\n",
      "75%        64.00  22,143.00      21.00      21.99  2016-01-01 00:00:00\n",
      "max        79.00  90,090.00   1,251.00  13,999.90  2016-01-01 00:00:00\n",
      "std        23.19  13,059.43      31.47      70.18                  NaN\n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_bif.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Cantidad NaN, Porcentaje NaN (%)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "bif_nan = df_bif.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "bif_porcentaje_nan = (bif_nan / len(df_bif)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "bif_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': bif_nan,\n",
    "    'Porcentaje NaN (%)': bif_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "bif_nan_info = bif_nan_info[bif_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(bif_nan_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en 'BegInvFINAL12312016_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_ip.to_csv('BegInvFINAL12312016_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'BegInvFINAL12312016_limp.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Tabla a analizar EndInvFINAL12312016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_eif = pd.read_csv('EndInvFINAL12312016.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId     object\n",
      "Store            int64\n",
      "City            object\n",
      "Brand            int64\n",
      "Description     object\n",
      "Size            object\n",
      "onHand           int64\n",
      "Price          float64\n",
      "endDate         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verificamos tipo de datos\n",
    "print(df_eif.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId            object\n",
      "Store                   int64\n",
      "City                   object\n",
      "Brand                   int64\n",
      "Description            object\n",
      "Size                   object\n",
      "onHand                  int64\n",
      "Price                 float64\n",
      "endDate        datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte endtDate en fecha\n",
    "\n",
    "df_eif['endDate'] = pd.to_datetime(df_eif['endDate'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_eif.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (224489, 9)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_eif.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         InventoryId  Store          City  Brand                  Description  \\\n",
      "0  1_HARDERSFIELD_58      1  HARDERSFIELD     58  Gekkeikan Black & Gold Sake   \n",
      "1  1_HARDERSFIELD_62      1  HARDERSFIELD     62     Herradura Silver Tequila   \n",
      "2  1_HARDERSFIELD_63      1  HARDERSFIELD     63   Herradura Reposado Tequila   \n",
      "3  1_HARDERSFIELD_72      1  HARDERSFIELD     72         No. 3 London Dry Gin   \n",
      "4  1_HARDERSFIELD_75      1  HARDERSFIELD     75    Three Olives Tomato Vodka   \n",
      "\n",
      "    Size  onHand  Price    endDate  \n",
      "0  750mL      11  12.99 2016-12-31  \n",
      "1  750mL       7  36.99 2016-12-31  \n",
      "2  750mL       7  38.99 2016-12-31  \n",
      "3  750mL       4  34.99 2016-12-31  \n",
      "4  750mL       7  14.99 2016-12-31  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_eif.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 224489 entries, 0 to 224488\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   InventoryId  224489 non-null  object        \n",
      " 1   Store        224489 non-null  int64         \n",
      " 2   City         223205 non-null  object        \n",
      " 3   Brand        224489 non-null  int64         \n",
      " 4   Description  224489 non-null  object        \n",
      " 5   Size         224489 non-null  object        \n",
      " 6   onHand       224489 non-null  int64         \n",
      " 7   Price        224489 non-null  float64       \n",
      " 8   endDate      224489 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(4)\n",
      "memory usage: 15.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_eif.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Store      Brand     onHand      Price              endDate\n",
      "count 224,489.00 224,489.00 224,489.00 224,489.00               224489\n",
      "mean       43.51  14,356.37      21.76      23.59  2016-12-31 00:00:00\n",
      "min         1.00      58.00       0.00       0.49  2016-12-31 00:00:00\n",
      "25%        23.00   3,798.00       7.00       9.99  2016-12-31 00:00:00\n",
      "50%        44.00   8,259.00      12.00      14.99  2016-12-31 00:00:00\n",
      "75%        66.00  23,965.00      22.00      23.49  2016-12-31 00:00:00\n",
      "max        81.00  90,631.00   3,676.00  13,999.90  2016-12-31 00:00:00\n",
      "std        23.33  13,118.47      37.23      79.20                  NaN\n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_eif.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cantidad NaN  Porcentaje NaN (%)\n",
      "City          1284                0.57\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "eif_nan = df_eif.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "eif_porcentaje_nan = (eif_nan / len(df_eif)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "eif_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': eif_nan,\n",
    "    'Porcentaje NaN (%)': eif_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "eif_nan_info = eif_nan_info[eif_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(eif_nan_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores nulos unicamente en los datos referidos a ciudad, se procede a analizarlos para rellenarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>City</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>onHand</th>\n",
       "      <th>Price</th>\n",
       "      <th>endDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113895</th>\n",
       "      <td>46__58</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>Gekkeikan Black &amp; Gold Sake</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113896</th>\n",
       "      <td>46__62</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62</td>\n",
       "      <td>Herradura Silver Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>36.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113897</th>\n",
       "      <td>46__63</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63</td>\n",
       "      <td>Herradura Reposado Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113898</th>\n",
       "      <td>46__77</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>Three Olives Espresso Vodka</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>14.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113899</th>\n",
       "      <td>46__106</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106</td>\n",
       "      <td>Mr Boston Peach Schnapps</td>\n",
       "      <td>Liter</td>\n",
       "      <td>0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115174</th>\n",
       "      <td>46__46447</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46447</td>\n",
       "      <td>Gascon Malbec Mendoza</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>10.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115175</th>\n",
       "      <td>46__46458</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46458</td>\n",
       "      <td>Layer Cake Barosa Shiraz</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>15.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115176</th>\n",
       "      <td>46__46476</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46476</td>\n",
       "      <td>Tilia Malbec Mendoza</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115177</th>\n",
       "      <td>46__46764</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46764</td>\n",
       "      <td>Clayhouse Adobe Red Paso Rbl</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>11.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115178</th>\n",
       "      <td>46__46830</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46830</td>\n",
       "      <td>Pacific Rim Sweet Rsl</td>\n",
       "      <td>750mL</td>\n",
       "      <td>0</td>\n",
       "      <td>8.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       InventoryId  Store City  Brand                   Description   Size  \\\n",
       "113895      46__58     46  NaN     58   Gekkeikan Black & Gold Sake  750mL   \n",
       "113896      46__62     46  NaN     62      Herradura Silver Tequila  750mL   \n",
       "113897      46__63     46  NaN     63    Herradura Reposado Tequila  750mL   \n",
       "113898      46__77     46  NaN     77   Three Olives Espresso Vodka  750mL   \n",
       "113899     46__106     46  NaN    106      Mr Boston Peach Schnapps  Liter   \n",
       "...            ...    ...  ...    ...                           ...    ...   \n",
       "115174   46__46447     46  NaN  46447         Gascon Malbec Mendoza  750mL   \n",
       "115175   46__46458     46  NaN  46458      Layer Cake Barosa Shiraz  750mL   \n",
       "115176   46__46476     46  NaN  46476          Tilia Malbec Mendoza  750mL   \n",
       "115177   46__46764     46  NaN  46764  Clayhouse Adobe Red Paso Rbl  750mL   \n",
       "115178   46__46830     46  NaN  46830         Pacific Rim Sweet Rsl  750mL   \n",
       "\n",
       "        onHand  Price    endDate  \n",
       "113895       0  12.99 2016-12-31  \n",
       "113896       0  36.99 2016-12-31  \n",
       "113897       0  38.99 2016-12-31  \n",
       "113898       0  14.99 2016-12-31  \n",
       "113899       0   4.49 2016-12-31  \n",
       "...        ...    ...        ...  \n",
       "115174       0  10.99 2016-12-31  \n",
       "115175       0  15.99 2016-12-31  \n",
       "115176       0   9.99 2016-12-31  \n",
       "115177       0  11.99 2016-12-31  \n",
       "115178       0   8.99 2016-12-31  \n",
       "\n",
       "[1284 rows x 9 columns]"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creamos un df unicamente con las city nulas para su analisis\n",
    "\n",
    "df_eif_nulos = df_eif[df_eif.isnull().any(axis=1)]\n",
    "df_eif_nulos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualizamos que al parecer, los unicos nulos se encuentran en la store 46, por lo que lo verificamos y trataremos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Limpieza de Datos - Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store\n",
       "46    1284\n",
       "dtype: int64"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chequeo de nulos por store\n",
    "\n",
    "df_eif[df_eif['Description'].notnull() & (df_eif['Store'] == 46)].groupby('Store').size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se confima la hipotesis de nulos, se procede a analizar si store es un codigo para cada city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Hay ciudades con m√°s de una tienda:\n",
      "City\n",
      "DONCASTER       2\n",
      "EANVERNESS      3\n",
      "GOULCREST       2\n",
      "HARDERSFIELD    2\n",
      "HORNSEY         4\n",
      "LARNWICK        2\n",
      "MOUNTMEND       4\n",
      "Name: Store, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Contar cu√°ntas tiendas (\"Store\") hay por cada ciudad (\"City\")\n",
    "store_count_per_city = df_eif.groupby('City')['Store'].nunique()\n",
    "\n",
    "# Filtrar ciudades que tienen m√°s de una tienda\n",
    "multiple_stores = store_count_per_city[store_count_per_city > 1]\n",
    "\n",
    "# Mostrar resultado\n",
    "if multiple_stores.empty:\n",
    "    print(\"‚úÖ Cada ciudad tiene solo una tienda.\")\n",
    "else:\n",
    "    print(\"‚ùå Hay ciudades con m√°s de una tienda:\")\n",
    "    print(multiple_stores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "al haber ciudades con mas de un codigo de store, se confirma que store no es un codigo de ciudad sino de tienda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [InventoryId, Store, City, Brand, Description, Size, onHand, Price, endDate]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# se analiza si hay algun dato de la store 46 con city para rellenerlo\n",
    "\n",
    "df_store_46_city_no_null = df_eif[(df_eif['Store'] == 46) & (df_eif['City'].notnull())]\n",
    "print(df_store_46_city_no_null)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se analizar√° si la tabla generada df_bif que contiene informacion de city y store esta relacionada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el DataFrame con las columnas 'Store' y 'City' de las tablas df_bif y df_eif \n",
    "df_sc_bif = df_bif[['Store', 'City']].copy()\n",
    "df_sc_eif = df_eif[['Store', 'City']].copy()\n",
    "\n",
    "\n",
    "# Crear una nueva columna 'Store_City' que contiene la concatenaci√≥n de 'Store' y 'City'\n",
    "df_sc_bif['Store_City'] = df_sc_bif['Store'].astype(str) + ' - ' + df_sc_bif['City']\n",
    "df_sc_eif['Store_City'] = df_sc_eif['Store'].astype(str) + ' - ' + df_sc_eif['City']\n",
    "\n",
    "# Generar df con store_city unicas\n",
    "df_sc_bif_unicas = df_sc_bif[['Store_City']].drop_duplicates()\n",
    "df_sc_eif_unicas = df_sc_eif[['Store_City']].drop_duplicates()\n",
    "\n",
    "# Seleccionar solo la columna 'Store_City' y reiniciar el √≠ndice\n",
    "df_filtered_bif = df_sc_bif_unicas[['Store_City']].reset_index(drop=True)\n",
    "df_filtered_eif = df_sc_eif_unicas[['Store_City']].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 bif               eif\n",
      "0   1 - HARDERSFIELD  1 - HARDERSFIELD\n",
      "1       2 - ASHBORNE      2 - ASHBORNE\n",
      "2        3 - HORNSEY       3 - HORNSEY\n",
      "3     4 - EANVERNESS    4 - EANVERNESS\n",
      "4         5 - SUTTON        5 - SUTTON\n",
      "..               ...               ...\n",
      "75    76 - DONCASTER    76 - DONCASTER\n",
      "76     77 - TAMWORTH     77 - TAMWORTH\n",
      "77    78 - EASTHAVEN    78 - EASTHAVEN\n",
      "78    79 - BALLYMENA    79 - BALLYMENA\n",
      "79               NaN     81 - PEMBROKE\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar las columnas de inter√©s de cada DataFrame\n",
    "Store_City = pd.DataFrame({\n",
    "    'bif': df_filtered_bif['Store_City'],  # Columna 'Store_City' de df_filtered_bif\n",
    "    'eif': df_filtered_eif['Store_City']   # Columna 'Store_City' de df_filtered_eif\n",
    "})\n",
    "\n",
    "# Ver el nuevo DataFrame\n",
    "print(Store_City)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 bif               eif check\n",
      "0   1 - HARDERSFIELD  1 - HARDERSFIELD    ok\n",
      "1       2 - ASHBORNE      2 - ASHBORNE    ok\n",
      "2        3 - HORNSEY       3 - HORNSEY    ok\n",
      "3     4 - EANVERNESS    4 - EANVERNESS    ok\n",
      "4         5 - SUTTON        5 - SUTTON    ok\n",
      "..               ...               ...   ...\n",
      "75    76 - DONCASTER    76 - DONCASTER    ok\n",
      "76     77 - TAMWORTH     77 - TAMWORTH    ok\n",
      "77    78 - EASTHAVEN    78 - EASTHAVEN    ok\n",
      "78    79 - BALLYMENA    79 - BALLYMENA    ok\n",
      "79               NaN     81 - PEMBROKE   ver\n",
      "\n",
      "[80 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Crear una nueva columna 'comparison' que compare 'bif' y 'eif'\n",
    "Store_City['check'] = Store_City.apply(lambda row: 'ok' if row['bif'] == row['eif'] else 'ver', axis=1)\n",
    "\n",
    "# Ver el DataFrame resultante\n",
    "print(Store_City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 bif            eif check\n",
      "45  46 - TYWARDREATH            NaN   ver\n",
      "79               NaN  81 - PEMBROKE   ver\n"
     ]
    }
   ],
   "source": [
    "# Filtrar el DataFrame por las filas donde 'comparison' es igual a 'ver'\n",
    "Store_City_ver = Store_City[Store_City['check'] == 'ver']\n",
    "\n",
    "# Ver el DataFrame filtrado\n",
    "print(Store_City_ver)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se visualiza que la store 46 faltante es la city de \"TYWARDREATH\" y se procede a agregarla y que en el dataframe InVoicePurchases no hubo inventario en la tienda 81 \"PEMBROKE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se carga la tienda city de la tienda 46\n",
    "df_eif.loc[(df_eif['Store'] == 46) & (df_eif['City'].isnull()), 'City'] = 'TYWARDREATH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos despu√©s de la limpieza:\n",
      " InventoryId    0\n",
      "Store          0\n",
      "City           0\n",
      "Brand          0\n",
      "Description    0\n",
      "Size           0\n",
      "onHand         0\n",
      "Price          0\n",
      "endDate        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de la cantidad de valores nulos en cada columna\n",
    "\n",
    "print(\"Valores nulos despu√©s de la limpieza:\\n\", df_eif.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en 'EndInvFINAL12312016_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_eif.to_csv('EndInvFINAL12312016_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'EndInvFINAL12312016_limp.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Tabla a analizar SalesFINAL12312016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_sf = pd.read_csv('SalesFINAL12312016.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId        object\n",
      "Store               int64\n",
      "Brand               int64\n",
      "Description        object\n",
      "Size               object\n",
      "SalesQuantity       int64\n",
      "SalesDollars      float64\n",
      "SalesPrice        float64\n",
      "SalesDate          object\n",
      "Volume              int64\n",
      "Classification      int64\n",
      "ExciseTax         float64\n",
      "VendorNo            int64\n",
      "VendorName         object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verificamos tipo de datos\n",
    "print(df_sf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId               object\n",
      "Store                      int64\n",
      "Brand                      int64\n",
      "Description               object\n",
      "Size                      object\n",
      "SalesQuantity              int64\n",
      "SalesDollars             float64\n",
      "SalesPrice               float64\n",
      "SalesDate         datetime64[ns]\n",
      "Volume                     int64\n",
      "Classification             int64\n",
      "ExciseTax                float64\n",
      "VendorNo                   int64\n",
      "VendorName                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte endtDate en fecha\n",
    "\n",
    "df_sf['SalesDate'] = pd.to_datetime(df_sf['SalesDate'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_sf.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (1048575, 14)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_sf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           InventoryId  Store  Brand                 Description        Size  \\\n",
      "0  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "1  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "2  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "3  1_HARDERSFIELD_1004      1   1004  Jim Beam w/2 Rocks Glasses       750mL   \n",
      "4  1_HARDERSFIELD_1005      1   1005     Maker's Mark Combo Pack  375mL 2 Pk   \n",
      "\n",
      "   SalesQuantity  SalesDollars  SalesPrice  SalesDate  Volume  Classification  \\\n",
      "0              1         16.49       16.49 2016-01-01     750               1   \n",
      "1              2         32.98       16.49 2016-01-02     750               1   \n",
      "2              1         16.49       16.49 2016-01-03     750               1   \n",
      "3              1         14.49       14.49 2016-01-08     750               1   \n",
      "4              2         69.98       34.99 2016-01-09     375               1   \n",
      "\n",
      "   ExciseTax  VendorNo                   VendorName  \n",
      "0       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "1       1.57     12546  JIM BEAM BRANDS COMPANY      \n",
      "2       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "3       0.79     12546  JIM BEAM BRANDS COMPANY      \n",
      "4       0.79     12546  JIM BEAM BRANDS COMPANY      \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_sf.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count    Dtype         \n",
      "---  ------          --------------    -----         \n",
      " 0   InventoryId     1048575 non-null  object        \n",
      " 1   Store           1048575 non-null  int64         \n",
      " 2   Brand           1048575 non-null  int64         \n",
      " 3   Description     1048575 non-null  object        \n",
      " 4   Size            1048575 non-null  object        \n",
      " 5   SalesQuantity   1048575 non-null  int64         \n",
      " 6   SalesDollars    1048575 non-null  float64       \n",
      " 7   SalesPrice      1048575 non-null  float64       \n",
      " 8   SalesDate       1048575 non-null  datetime64[ns]\n",
      " 9   Volume          1048575 non-null  int64         \n",
      " 10  Classification  1048575 non-null  int64         \n",
      " 11  ExciseTax       1048575 non-null  float64       \n",
      " 12  VendorNo        1048575 non-null  int64         \n",
      " 13  VendorName      1048575 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(3), int64(6), object(4)\n",
      "memory usage: 112.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_sf.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Store        Brand  SalesQuantity  SalesDollars   SalesPrice  \\\n",
      "count 1,048,575.00 1,048,575.00   1,048,575.00  1,048,575.00 1,048,575.00   \n",
      "mean         40.08    12,169.59           2.34         31.60        15.43   \n",
      "min           1.00        58.00           1.00          0.49         0.49   \n",
      "25%          15.00     3,680.00           1.00         10.99         8.99   \n",
      "50%          39.00     6,296.00           1.00         17.99        12.99   \n",
      "75%          64.00    17,954.00           2.00         31.99        18.99   \n",
      "max          79.00    90,089.00         432.00     13,279.97     4,999.99   \n",
      "std          24.36    12,419.21           3.51         65.70        14.05   \n",
      "\n",
      "                           SalesDate       Volume  Classification  \\\n",
      "count                        1048575 1,048,575.00    1,048,575.00   \n",
      "mean   2016-01-19 21:59:18.574636288       950.03            1.42   \n",
      "min              2016-01-01 00:00:00        50.00            1.00   \n",
      "25%              2016-01-10 00:00:00       750.00            1.00   \n",
      "50%              2016-01-19 00:00:00       750.00            1.00   \n",
      "75%              2016-01-28 00:00:00     1,500.00            2.00   \n",
      "max              2016-02-29 00:00:00    20,000.00            2.00   \n",
      "std                              NaN       714.27            0.49   \n",
      "\n",
      "         ExciseTax     VendorNo  \n",
      "count 1,048,575.00 1,048,575.00  \n",
      "mean          1.33     6,995.04  \n",
      "min           0.01         2.00  \n",
      "25%           0.16     3,252.00  \n",
      "50%           0.68     4,425.00  \n",
      "75%           1.57     9,552.00  \n",
      "max         378.52   173,357.00  \n",
      "std           3.41     8,426.74  \n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_sf.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Cantidad NaN, Porcentaje NaN (%)]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "sf_nan = df_sf.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "sf_porcentaje_nan = (sf_nan / len(df_sf)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "sf_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': sf_nan,\n",
    "    'Porcentaje NaN (%)': sf_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "sf_nan_info = sf_nan_info[sf_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(sf_nan_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en 'SalesFINAL12312016_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_sf.to_csv('SalesFINAL12312016_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'SalesFINAL12312016_limp.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Tabla a analizar PurchasesFINAL12312016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Carga y visualizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_pf = pd.read_csv('PurchasesFINAL12312016.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId        object\n",
      "Store               int64\n",
      "Brand               int64\n",
      "Description        object\n",
      "Size               object\n",
      "VendorNumber        int64\n",
      "VendorName         object\n",
      "PONumber            int64\n",
      "PODate             object\n",
      "ReceivingDate      object\n",
      "InvoiceDate        object\n",
      "PayDate            object\n",
      "PurchasePrice     float64\n",
      "Quantity            int64\n",
      "Dollars           float64\n",
      "Classification      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# verificamos tipo de datos\n",
    "print(df_pf.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InventoryId               object\n",
      "Store                      int64\n",
      "Brand                      int64\n",
      "Description               object\n",
      "Size                      object\n",
      "VendorNumber               int64\n",
      "VendorName                object\n",
      "PONumber                   int64\n",
      "PODate            datetime64[ns]\n",
      "ReceivingDate     datetime64[ns]\n",
      "InvoiceDate       datetime64[ns]\n",
      "PayDate           datetime64[ns]\n",
      "PurchasePrice            float64\n",
      "Quantity                   int64\n",
      "Dollars                  float64\n",
      "Classification             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte PODate en fecha\n",
    "\n",
    "df_pf['PODate'] = pd.to_datetime(df_pf['PODate'])\n",
    "df_pf['ReceivingDate'] = pd.to_datetime(df_pf['ReceivingDate'])\n",
    "df_pf['InvoiceDate'] = pd.to_datetime(df_pf['InvoiceDate'])\n",
    "df_pf['PayDate'] = pd.to_datetime(df_pf['PayDate'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_pf.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o del DataFrame: (2372474, 16)\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del DataFrame\n",
    "print(f\"Tama√±o del DataFrame: {df_pf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           InventoryId  Store  Brand                   Description   Size  \\\n",
      "0    69_MOUNTMEND_8412     69   8412     Tequila Ocho Plata Fresno  750mL   \n",
      "1     30_CULCHETH_5255     30   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "2    34_PITMERDEN_5215     34   5215  TGI Fridays Long Island Iced  1.75L   \n",
      "3  1_HARDERSFIELD_5255      1   5255  TGI Fridays Ultimte Mudslide  1.75L   \n",
      "4    76_DONCASTER_2034     76   2034     Glendalough Double Barrel  750mL   \n",
      "\n",
      "   VendorNumber                   VendorName  PONumber     PODate  \\\n",
      "0           105  ALTAMAR BRANDS LLC               8124 2015-12-21   \n",
      "1          4466  AMERICAN VINTAGE BEVERAGE        8137 2015-12-22   \n",
      "2          4466  AMERICAN VINTAGE BEVERAGE        8137 2015-12-22   \n",
      "3          4466  AMERICAN VINTAGE BEVERAGE        8137 2015-12-22   \n",
      "4           388  ATLANTIC IMPORTING COMPANY       8169 2015-12-24   \n",
      "\n",
      "  ReceivingDate InvoiceDate    PayDate  PurchasePrice  Quantity  Dollars  \\\n",
      "0    2016-01-02  2016-01-04 2016-02-16          35.71         6   214.26   \n",
      "1    2016-01-01  2016-01-07 2016-02-21           9.35         4    37.40   \n",
      "2    2016-01-02  2016-01-07 2016-02-21           9.41         5    47.05   \n",
      "3    2016-01-01  2016-01-07 2016-02-21           9.35         6    56.10   \n",
      "4    2016-01-02  2016-01-09 2016-02-16          21.32         5   106.60   \n",
      "\n",
      "   Classification  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas para entender la estructura de los datos\n",
    "\n",
    "print(df_pf.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2372474 entries, 0 to 2372473\n",
      "Data columns (total 16 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   InventoryId     object        \n",
      " 1   Store           int64         \n",
      " 2   Brand           int64         \n",
      " 3   Description     object        \n",
      " 4   Size            object        \n",
      " 5   VendorNumber    int64         \n",
      " 6   VendorName      object        \n",
      " 7   PONumber        int64         \n",
      " 8   PODate          datetime64[ns]\n",
      " 9   ReceivingDate   datetime64[ns]\n",
      " 10  InvoiceDate     datetime64[ns]\n",
      " 11  PayDate         datetime64[ns]\n",
      " 12  PurchasePrice   float64       \n",
      " 13  Quantity        int64         \n",
      " 14  Dollars         float64       \n",
      " 15  Classification  int64         \n",
      "dtypes: datetime64[ns](4), float64(2), int64(6), object(4)\n",
      "memory usage: 289.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Mostrar informaci√≥n general (tipos de datos, valores nulos)\n",
    "\n",
    "print(df_pf.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Store        Brand  VendorNumber     PONumber  \\\n",
      "count 2,372,474.00 2,372,474.00  2,372,474.00 2,372,474.00   \n",
      "mean         44.65    12,418.64      6,886.44    11,040.94   \n",
      "min           1.00        58.00          2.00     8,106.00   \n",
      "25%          25.00     3,639.00      3,252.00     9,761.00   \n",
      "50%          48.00     6,523.00      4,425.00    11,103.00   \n",
      "75%          67.00    18,877.00      9,552.00    12,397.00   \n",
      "max          81.00    90,631.00    201,359.00    13,661.00   \n",
      "std          23.51    12,557.28      8,066.69     1,565.34   \n",
      "\n",
      "                              PODate                  ReceivingDate  \\\n",
      "count                        2372474                        2372474   \n",
      "mean   2016-07-04 13:34:14.973836544  2016-07-12 04:28:06.818402048   \n",
      "min              2015-12-20 00:00:00            2016-01-01 00:00:00   \n",
      "25%              2016-04-12 00:00:00            2016-04-20 00:00:00   \n",
      "50%              2016-07-07 00:00:00            2016-07-15 00:00:00   \n",
      "75%              2016-09-30 00:00:00            2016-10-07 00:00:00   \n",
      "max              2016-12-23 00:00:00            2016-12-31 00:00:00   \n",
      "std                              NaN                            NaN   \n",
      "\n",
      "                         InvoiceDate                        PayDate  \\\n",
      "count                        2372474                        2372474   \n",
      "mean   2016-07-21 01:24:37.535094784  2016-08-25 17:13:18.406053120   \n",
      "min              2016-01-04 00:00:00            2016-02-04 00:00:00   \n",
      "25%              2016-04-29 00:00:00            2016-06-02 00:00:00   \n",
      "50%              2016-07-25 00:00:00            2016-08-29 00:00:00   \n",
      "75%              2016-10-17 00:00:00            2016-11-24 00:00:00   \n",
      "max              2017-01-10 00:00:00            2017-02-19 00:00:00   \n",
      "std                              NaN                            NaN   \n",
      "\n",
      "       PurchasePrice     Quantity      Dollars  Classification  \n",
      "count   2,372,474.00 2,372,474.00 2,372,474.00    2,372,474.00  \n",
      "mean           12.05        14.16       135.68            1.44  \n",
      "min             0.00         1.00         0.00            1.00  \n",
      "25%             6.12         6.00        49.26            1.00  \n",
      "50%             9.22        10.00        83.93            1.00  \n",
      "75%            14.49        12.00       140.52            2.00  \n",
      "max         5,681.81     3,816.00    50,175.70            2.00  \n",
      "std            17.95        23.45       281.66            0.50  \n"
     ]
    }
   ],
   "source": [
    "# Resumen estad√≠stico de las variables num√©ricas (media, desviaci√≥n est√°ndar, percentiles)\n",
    "\n",
    "# Configuraci√≥n para formatear los n√∫meros en el DataFrame a xxx,xxx.xx ya que se puede analizar mejor los resultados\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "print(df_pf.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cantidad NaN  Porcentaje NaN (%)\n",
      "Size             3                0.00\n"
     ]
    }
   ],
   "source": [
    "# Calcular la cantidad de valores NaN por columna\n",
    "pf_nan = df_pf.isnull().sum()\n",
    "\n",
    "# Calcular el porcentaje de valores NaN por columna\n",
    "pf_porcentaje_nan = (pf_nan / len(df_pf)) * 100\n",
    "\n",
    "# Crear un DataFrame para visualizar la cantidad y el porcentaje de NaN por columna\n",
    "pf_nan_info = pd.DataFrame({\n",
    "    'Cantidad NaN': pf_nan,\n",
    "    'Porcentaje NaN (%)': pf_porcentaje_nan\n",
    "})\n",
    "\n",
    "# Filtrar el DataFrame para mostrar solo las columnas con cantidad NaN > 0\n",
    "pf_nan_info = pf_nan_info[pf_nan_info['Cantidad NaN'] > 0]\n",
    "\n",
    "# Imprimir el DataFrame con la cantidad y porcentaje de NaN por columna\n",
    "print(pf_nan_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Limpieza de Datos - Manejo de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros con 'Size' nulo:\n",
      "                        Description Size\n",
      "1109668    Pinnacle Rainbow Sherbet  NaN\n",
      "1112426      Skinnygirl Pina Colada  NaN\n",
      "1116302  Alabaster 07 Tinta de Toro  NaN\n",
      "\n",
      "Registros con la misma 'Description' pero con 'Size' no nulo:\n",
      "                      Description   Size\n",
      "26472      Skinnygirl Pina Colada  750mL\n",
      "134447   Pinnacle Rainbow Sherbet  750mL\n",
      "135201   Pinnacle Rainbow Sherbet  750mL\n",
      "135202   Pinnacle Rainbow Sherbet  750mL\n",
      "176514     Skinnygirl Pina Colada  750mL\n",
      "214731     Skinnygirl Pina Colada  750mL\n",
      "214955   Pinnacle Rainbow Sherbet  750mL\n",
      "215283   Pinnacle Rainbow Sherbet  750mL\n",
      "291013   Pinnacle Rainbow Sherbet  750mL\n",
      "366401     Skinnygirl Pina Colada  750mL\n",
      "366882     Skinnygirl Pina Colada  750mL\n",
      "367931     Skinnygirl Pina Colada  750mL\n",
      "406165   Pinnacle Rainbow Sherbet  750mL\n",
      "478946   Pinnacle Rainbow Sherbet  750mL\n",
      "631595     Skinnygirl Pina Colada  750mL\n",
      "760082     Skinnygirl Pina Colada  750mL\n",
      "761874     Skinnygirl Pina Colada  750mL\n",
      "1109305  Pinnacle Rainbow Sherbet  750mL\n"
     ]
    }
   ],
   "source": [
    "# Filtrar las filas donde 'size' es NaN\n",
    "df_size_nan = df_pf[df_pf['Size'].isnull()]\n",
    "\n",
    "# Verificar si existen registros con la misma 'description' pero con 'size' no nulo\n",
    "df_matched = df_pf[df_pf['Description'].isin(df_size_nan['Description']) & df_pf['Size'].notnull()]\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(\"Registros con 'Size' nulo:\")\n",
    "print(df_size_nan[['Description', 'Size']])\n",
    "\n",
    "print(\"\\nRegistros con la misma 'Description' pero con 'Size' no nulo:\")\n",
    "print(df_matched[['Description', 'Size']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el analisis anterior, se decide rellenar los valor nulos con 750mL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar los valores NaN\n",
    "\n",
    "df_pf['Size'] = df_pf['Size'].fillna('750mL')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos despu√©s de la limpieza:\n",
      " InventoryId       0\n",
      "Store             0\n",
      "Brand             0\n",
      "Description       0\n",
      "Size              0\n",
      "VendorNumber      0\n",
      "VendorName        0\n",
      "PONumber          0\n",
      "PODate            0\n",
      "ReceivingDate     0\n",
      "InvoiceDate       0\n",
      "PayDate           0\n",
      "PurchasePrice     0\n",
      "Quantity          0\n",
      "Dollars           0\n",
      "Classification    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verificaci√≥n de la cantidad de valores nulos en cada columna\n",
    "\n",
    "print(\"Valores nulos despu√©s de la limpieza:\\n\", df_pf.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los datos filtrados se han guardado correctamente en 'PurchasesFINAL12312016_limp.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Guardar los datos filtrados en un archivo CSV\n",
    "\n",
    "df_pf.to_csv('PurchasesFINAL12312016_limp.csv', index=False, sep=',')\n",
    "\n",
    "print(\"Los datos filtrados se han guardado correctamente en 'PurchasesFINAL12312016_limp.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>City</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>onHand</th>\n",
       "      <th>Price</th>\n",
       "      <th>startDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_HARDERSFIELD_58</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>58</td>\n",
       "      <td>Gekkeikan Black &amp; Gold Sake</td>\n",
       "      <td>750mL</td>\n",
       "      <td>8</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_HARDERSFIELD_60</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>60</td>\n",
       "      <td>Canadian Club 1858 VAP</td>\n",
       "      <td>750mL</td>\n",
       "      <td>7</td>\n",
       "      <td>10.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_HARDERSFIELD_62</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>62</td>\n",
       "      <td>Herradura Silver Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>6</td>\n",
       "      <td>36.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_HARDERSFIELD_63</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>63</td>\n",
       "      <td>Herradura Reposado Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>3</td>\n",
       "      <td>38.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_HARDERSFIELD_72</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>72</td>\n",
       "      <td>No. 3 London Dry Gin</td>\n",
       "      <td>750mL</td>\n",
       "      <td>6</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206524</th>\n",
       "      <td>79_BALLYMENA_46985</td>\n",
       "      <td>79</td>\n",
       "      <td>BALLYMENA</td>\n",
       "      <td>46985</td>\n",
       "      <td>Rodney Strong Cab Svgn Alexa</td>\n",
       "      <td>750mL</td>\n",
       "      <td>13</td>\n",
       "      <td>22.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206525</th>\n",
       "      <td>79_BALLYMENA_47014</td>\n",
       "      <td>79</td>\n",
       "      <td>BALLYMENA</td>\n",
       "      <td>47014</td>\n",
       "      <td>Juan Gil Jumilla Rd</td>\n",
       "      <td>750mL</td>\n",
       "      <td>13</td>\n",
       "      <td>13.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206526</th>\n",
       "      <td>79_BALLYMENA_47090</td>\n",
       "      <td>79</td>\n",
       "      <td>BALLYMENA</td>\n",
       "      <td>47090</td>\n",
       "      <td>Napa Cellars Cab Svgn Napa</td>\n",
       "      <td>750mL</td>\n",
       "      <td>19</td>\n",
       "      <td>23.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206527</th>\n",
       "      <td>79_BALLYMENA_90011</td>\n",
       "      <td>79</td>\n",
       "      <td>BALLYMENA</td>\n",
       "      <td>90011</td>\n",
       "      <td>Ch Pichon Longville 12 Pauil</td>\n",
       "      <td>750mL</td>\n",
       "      <td>12</td>\n",
       "      <td>144.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206528</th>\n",
       "      <td>79_BALLYMENA_90089</td>\n",
       "      <td>79</td>\n",
       "      <td>BALLYMENA</td>\n",
       "      <td>90089</td>\n",
       "      <td>Ch Lynch Bages 12 Pauillac</td>\n",
       "      <td>750mL</td>\n",
       "      <td>24</td>\n",
       "      <td>119.99</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206529 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               InventoryId  Store          City  Brand  \\\n",
       "0        1_HARDERSFIELD_58      1  HARDERSFIELD     58   \n",
       "1        1_HARDERSFIELD_60      1  HARDERSFIELD     60   \n",
       "2        1_HARDERSFIELD_62      1  HARDERSFIELD     62   \n",
       "3        1_HARDERSFIELD_63      1  HARDERSFIELD     63   \n",
       "4        1_HARDERSFIELD_72      1  HARDERSFIELD     72   \n",
       "...                    ...    ...           ...    ...   \n",
       "206524  79_BALLYMENA_46985     79     BALLYMENA  46985   \n",
       "206525  79_BALLYMENA_47014     79     BALLYMENA  47014   \n",
       "206526  79_BALLYMENA_47090     79     BALLYMENA  47090   \n",
       "206527  79_BALLYMENA_90011     79     BALLYMENA  90011   \n",
       "206528  79_BALLYMENA_90089     79     BALLYMENA  90089   \n",
       "\n",
       "                         Description   Size  onHand  Price  startDate  \n",
       "0        Gekkeikan Black & Gold Sake  750mL       8  12.99 2016-01-01  \n",
       "1             Canadian Club 1858 VAP  750mL       7  10.99 2016-01-01  \n",
       "2           Herradura Silver Tequila  750mL       6  36.99 2016-01-01  \n",
       "3         Herradura Reposado Tequila  750mL       3  38.99 2016-01-01  \n",
       "4               No. 3 London Dry Gin  750mL       6  34.99 2016-01-01  \n",
       "...                              ...    ...     ...    ...        ...  \n",
       "206524  Rodney Strong Cab Svgn Alexa  750mL      13  22.99 2016-01-01  \n",
       "206525           Juan Gil Jumilla Rd  750mL      13  13.99 2016-01-01  \n",
       "206526    Napa Cellars Cab Svgn Napa  750mL      19  23.99 2016-01-01  \n",
       "206527  Ch Pichon Longville 12 Pauil  750mL      12 144.99 2016-01-01  \n",
       "206528    Ch Lynch Bages 12 Pauillac  750mL      24 119.99 2016-01-01  \n",
       "\n",
       "[206529 rows x 9 columns]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InventoryId</th>\n",
       "      <th>Store</th>\n",
       "      <th>City</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Size</th>\n",
       "      <th>onHand</th>\n",
       "      <th>Price</th>\n",
       "      <th>endDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_HARDERSFIELD_58</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>58</td>\n",
       "      <td>Gekkeikan Black &amp; Gold Sake</td>\n",
       "      <td>750mL</td>\n",
       "      <td>11</td>\n",
       "      <td>12.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_HARDERSFIELD_62</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>62</td>\n",
       "      <td>Herradura Silver Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>7</td>\n",
       "      <td>36.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_HARDERSFIELD_63</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>63</td>\n",
       "      <td>Herradura Reposado Tequila</td>\n",
       "      <td>750mL</td>\n",
       "      <td>7</td>\n",
       "      <td>38.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_HARDERSFIELD_72</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>72</td>\n",
       "      <td>No. 3 London Dry Gin</td>\n",
       "      <td>750mL</td>\n",
       "      <td>4</td>\n",
       "      <td>34.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_HARDERSFIELD_75</td>\n",
       "      <td>1</td>\n",
       "      <td>HARDERSFIELD</td>\n",
       "      <td>75</td>\n",
       "      <td>Three Olives Tomato Vodka</td>\n",
       "      <td>750mL</td>\n",
       "      <td>7</td>\n",
       "      <td>14.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224484</th>\n",
       "      <td>81_PEMBROKE_90087</td>\n",
       "      <td>81</td>\n",
       "      <td>PEMBROKE</td>\n",
       "      <td>90087</td>\n",
       "      <td>Ch Mouton Rothschild 12 Paui</td>\n",
       "      <td>750mL</td>\n",
       "      <td>3</td>\n",
       "      <td>469.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224485</th>\n",
       "      <td>81_PEMBROKE_90088</td>\n",
       "      <td>81</td>\n",
       "      <td>PEMBROKE</td>\n",
       "      <td>90088</td>\n",
       "      <td>Ch Le Petite Mouton 12 Pauil</td>\n",
       "      <td>750mL</td>\n",
       "      <td>3</td>\n",
       "      <td>134.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224486</th>\n",
       "      <td>81_PEMBROKE_90089</td>\n",
       "      <td>81</td>\n",
       "      <td>PEMBROKE</td>\n",
       "      <td>90089</td>\n",
       "      <td>Ch Lynch Bages 12 Pauillac</td>\n",
       "      <td>750mL</td>\n",
       "      <td>3</td>\n",
       "      <td>119.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224487</th>\n",
       "      <td>81_PEMBROKE_90090</td>\n",
       "      <td>81</td>\n",
       "      <td>PEMBROKE</td>\n",
       "      <td>90090</td>\n",
       "      <td>Ch Lafite Rothschild 12</td>\n",
       "      <td>750mL</td>\n",
       "      <td>3</td>\n",
       "      <td>649.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224488</th>\n",
       "      <td>81_PEMBROKE_90604</td>\n",
       "      <td>81</td>\n",
       "      <td>PEMBROKE</td>\n",
       "      <td>90604</td>\n",
       "      <td>Ch Lynch Bages Pauilac</td>\n",
       "      <td>750mL</td>\n",
       "      <td>2</td>\n",
       "      <td>119.99</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>224489 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              InventoryId  Store          City  Brand  \\\n",
       "0       1_HARDERSFIELD_58      1  HARDERSFIELD     58   \n",
       "1       1_HARDERSFIELD_62      1  HARDERSFIELD     62   \n",
       "2       1_HARDERSFIELD_63      1  HARDERSFIELD     63   \n",
       "3       1_HARDERSFIELD_72      1  HARDERSFIELD     72   \n",
       "4       1_HARDERSFIELD_75      1  HARDERSFIELD     75   \n",
       "...                   ...    ...           ...    ...   \n",
       "224484  81_PEMBROKE_90087     81      PEMBROKE  90087   \n",
       "224485  81_PEMBROKE_90088     81      PEMBROKE  90088   \n",
       "224486  81_PEMBROKE_90089     81      PEMBROKE  90089   \n",
       "224487  81_PEMBROKE_90090     81      PEMBROKE  90090   \n",
       "224488  81_PEMBROKE_90604     81      PEMBROKE  90604   \n",
       "\n",
       "                         Description   Size  onHand  Price    endDate  \n",
       "0        Gekkeikan Black & Gold Sake  750mL      11  12.99 2016-12-31  \n",
       "1           Herradura Silver Tequila  750mL       7  36.99 2016-12-31  \n",
       "2         Herradura Reposado Tequila  750mL       7  38.99 2016-12-31  \n",
       "3               No. 3 London Dry Gin  750mL       4  34.99 2016-12-31  \n",
       "4          Three Olives Tomato Vodka  750mL       7  14.99 2016-12-31  \n",
       "...                              ...    ...     ...    ...        ...  \n",
       "224484  Ch Mouton Rothschild 12 Paui  750mL       3 469.99 2016-12-31  \n",
       "224485  Ch Le Petite Mouton 12 Pauil  750mL       3 134.99 2016-12-31  \n",
       "224486    Ch Lynch Bages 12 Pauillac  750mL       3 119.99 2016-12-31  \n",
       "224487       Ch Lafite Rothschild 12  750mL       3 649.99 2016-12-31  \n",
       "224488        Ch Lynch Bages Pauilac  750mL       2 119.99 2016-12-31  \n",
       "\n",
       "[224489 rows x 9 columns]"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ejecuto y cargo pourchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lee el archivo CSV con el delimitador especificado\n",
    "\n",
    "df_pf1= pd.read_csv('PurchasesFINAL12312016_limp.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'InventoryId'\n",
      "'Store'\n",
      "'Brand'\n",
      "'Description'\n",
      "'Size'\n",
      "'VendorNumber'\n",
      "'VendorName'\n",
      "'PONumber'\n",
      "'PODate'\n",
      "'ReceivingDate'\n",
      "'InvoiceDate'\n",
      "'PayDate'\n",
      "'PurchasePrice'\n",
      "'Quantity'\n",
      "'Dollars'\n",
      "'Classification'\n"
     ]
    }
   ],
   "source": [
    "#listo las columnas para renombrarlas\n",
    "for col in df_pf1.columns:\n",
    "    print(f\"'{col}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.4 Adaptaci√≥n a Base de Daatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_inventario</th>\n",
       "      <th>id_store</th>\n",
       "      <th>id_brand</th>\n",
       "      <th>id_vendor_number</th>\n",
       "      <th>id_po_number</th>\n",
       "      <th>receiving_date</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>quantity_purchases</th>\n",
       "      <th>total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69_MOUNTMEND_8412</td>\n",
       "      <td>69</td>\n",
       "      <td>8412</td>\n",
       "      <td>105</td>\n",
       "      <td>8124</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>35.71</td>\n",
       "      <td>6</td>\n",
       "      <td>214.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30_CULCHETH_5255</td>\n",
       "      <td>30</td>\n",
       "      <td>5255</td>\n",
       "      <td>4466</td>\n",
       "      <td>8137</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>9.35</td>\n",
       "      <td>4</td>\n",
       "      <td>37.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34_PITMERDEN_5215</td>\n",
       "      <td>34</td>\n",
       "      <td>5215</td>\n",
       "      <td>4466</td>\n",
       "      <td>8137</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>9.41</td>\n",
       "      <td>5</td>\n",
       "      <td>47.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_HARDERSFIELD_5255</td>\n",
       "      <td>1</td>\n",
       "      <td>5255</td>\n",
       "      <td>4466</td>\n",
       "      <td>8137</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>9.35</td>\n",
       "      <td>6</td>\n",
       "      <td>56.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76_DONCASTER_2034</td>\n",
       "      <td>76</td>\n",
       "      <td>2034</td>\n",
       "      <td>388</td>\n",
       "      <td>8169</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>21.32</td>\n",
       "      <td>5</td>\n",
       "      <td>106.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372469</th>\n",
       "      <td>49_GARIGILL_22298</td>\n",
       "      <td>49</td>\n",
       "      <td>22298</td>\n",
       "      <td>90058</td>\n",
       "      <td>13593</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>8.06</td>\n",
       "      <td>12</td>\n",
       "      <td>96.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372470</th>\n",
       "      <td>1_HARDERSFIELD_19556</td>\n",
       "      <td>1</td>\n",
       "      <td>19556</td>\n",
       "      <td>90058</td>\n",
       "      <td>13593</td>\n",
       "      <td>2016-12-27</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12</td>\n",
       "      <td>112.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372471</th>\n",
       "      <td>66_EANVERNESS_22297</td>\n",
       "      <td>66</td>\n",
       "      <td>22297</td>\n",
       "      <td>90058</td>\n",
       "      <td>13593</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>6.75</td>\n",
       "      <td>12</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372472</th>\n",
       "      <td>69_MOUNTMEND_19557</td>\n",
       "      <td>69</td>\n",
       "      <td>19557</td>\n",
       "      <td>90058</td>\n",
       "      <td>13593</td>\n",
       "      <td>2016-12-26</td>\n",
       "      <td>9.39</td>\n",
       "      <td>12</td>\n",
       "      <td>112.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372473</th>\n",
       "      <td>55_DRY GULCH_22298</td>\n",
       "      <td>55</td>\n",
       "      <td>22298</td>\n",
       "      <td>90058</td>\n",
       "      <td>13593</td>\n",
       "      <td>2016-12-28</td>\n",
       "      <td>8.06</td>\n",
       "      <td>12</td>\n",
       "      <td>96.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2372474 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id_inventario  id_store  id_brand  id_vendor_number  \\\n",
       "0           69_MOUNTMEND_8412        69      8412               105   \n",
       "1            30_CULCHETH_5255        30      5255              4466   \n",
       "2           34_PITMERDEN_5215        34      5215              4466   \n",
       "3         1_HARDERSFIELD_5255         1      5255              4466   \n",
       "4           76_DONCASTER_2034        76      2034               388   \n",
       "...                       ...       ...       ...               ...   \n",
       "2372469     49_GARIGILL_22298        49     22298             90058   \n",
       "2372470  1_HARDERSFIELD_19556         1     19556             90058   \n",
       "2372471   66_EANVERNESS_22297        66     22297             90058   \n",
       "2372472    69_MOUNTMEND_19557        69     19557             90058   \n",
       "2372473    55_DRY GULCH_22298        55     22298             90058   \n",
       "\n",
       "         id_po_number receiving_date  purchase_price  quantity_purchases  \\\n",
       "0                8124     2016-01-02           35.71                   6   \n",
       "1                8137     2016-01-01            9.35                   4   \n",
       "2                8137     2016-01-02            9.41                   5   \n",
       "3                8137     2016-01-01            9.35                   6   \n",
       "4                8169     2016-01-02           21.32                   5   \n",
       "...               ...            ...             ...                 ...   \n",
       "2372469         13593     2016-12-28            8.06                  12   \n",
       "2372470         13593     2016-12-27            9.39                  12   \n",
       "2372471         13593     2016-12-26            6.75                  12   \n",
       "2372472         13593     2016-12-26            9.39                  12   \n",
       "2372473         13593     2016-12-28            8.06                  12   \n",
       "\n",
       "         total_price  \n",
       "0             214.26  \n",
       "1              37.40  \n",
       "2              47.05  \n",
       "3              56.10  \n",
       "4             106.60  \n",
       "...              ...  \n",
       "2372469        96.72  \n",
       "2372470       112.68  \n",
       "2372471        81.00  \n",
       "2372472       112.68  \n",
       "2372473        96.72  \n",
       "\n",
       "[2372474 rows x 9 columns]"
      ]
     },
     "execution_count": 706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar solo los campos necesarios\n",
    "#  renombrarlos seg√∫n el formato de la imagen\n",
    "df_purchases = df_pf1.rename(columns={\n",
    "    'InventoryId': 'id_inventario',\n",
    "    'Store': 'id_store',\n",
    "    'Brand': 'id_brand',\n",
    "    'Description': 'description',\n",
    "    'Size': 'size',\n",
    "    'VendorNumber': 'id_vendor_number',\n",
    "    'VendorName': 'vendor_name',\n",
    "    'PONumber': 'id_po_number',\n",
    "    'PODate': 'po_date',\n",
    "    'ReceivingDate': 'receiving_date',\n",
    "    'InvoiceDate': 'invoice_date',\n",
    "    'PayDate': 'pay_date',\n",
    "    'PurchasePrice': 'purchase_price',\n",
    "    'Quantity': 'quantity_purchases',\n",
    "    'Dollars': 'total_price',\n",
    "    'Classification': 'classification'\n",
    "})\n",
    "\n",
    "[['id_inventario', 'id_store', 'id_brand', 'id_vendor_number', \n",
    "     'id_po_number', 'receiving_date', 'purchase_price', \n",
    "     'quantity_purchases', 'total_price']]\n",
    "\n",
    "df_purchases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar a dos decimales los datos de las columnas 'TotalAmount' y 'Freight'\n",
    "df_purchases['total_price'] = pd.to_numeric(df_purchases['total_price'], errors='coerce').round(2)\n",
    "df_purchases['purchase_price'] = pd.to_numeric(df_purchases['purchase_price'], errors='coerce').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_inventario          object\n",
       "id_store                int64\n",
       "id_brand                int64\n",
       "id_vendor_number        int64\n",
       "id_po_number            int64\n",
       "receiving_date         object\n",
       "purchase_price        float64\n",
       "quantity_purchases      int64\n",
       "total_price           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_purchases.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *3- Llenado de Tablas.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_inventario                 object\n",
      "id_store                       int64\n",
      "id_brand                       int64\n",
      "id_vendor_number               int64\n",
      "id_po_number                   int64\n",
      "receiving_date        datetime64[ns]\n",
      "purchase_price               float64\n",
      "quantity_purchases             int64\n",
      "total_price                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# convierte endtDate en fecha\n",
    "\n",
    "df_purchases['receiving_date'] = pd.to_datetime(df_purchases['receiving_date'])\n",
    "\n",
    "# Verificaci√≥n\n",
    "print(df_purchases.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir 'n' como el n√∫mero de filas de una parte\n",
    "n = len(df_purchases) // 4  # Esto divide el DataFrame en 4 partes\n",
    "\n",
    "# Dividir el DataFrame en partes\n",
    "df_purchases_part1 = df_purchases.iloc[:n]\n",
    "df_purchases_part2 = df_purchases.iloc[n:2 * n]\n",
    "df_purchases_part3 = df_purchases.iloc[2 * n:3 * n]\n",
    "df_purchases_part4 = df_purchases.iloc[3 * n:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al insertar datos en 'facts_purchase': ('23000', '[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The INSERT statement conflicted with the FOREIGN KEY constraint \"FK_facts_purchase_inventario\". The conflict occurred in database \"SpiritLiquor\", table \"dbo.inventario\", column \\'id_inventario\\'. (547) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)')\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Configuraci√≥n de conexi√≥n a SQL Server en Cloud SQL\n",
    "DB_HOST = \"34.176.175.250\"  # Reempl√°zalo con tu IP en GCP\n",
    "DB_NAME = \"SpiritLiquor\"  # Nombre de la base de datos\n",
    "DB_USER = \"sqlserver\"\n",
    "DB_PASSWORD = \"proyectofinal\"\n",
    "\n",
    "# Cadena de conexi√≥n ODBC\n",
    "conn_str = f\"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={DB_HOST};DATABASE={DB_NAME};UID={DB_USER};PWD={DB_PASSWORD}\"\n",
    "\n",
    "try:\n",
    "    # Conectar a SQL Server\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insertar los datos del DataFrame en la tabla facts_purchase\n",
    "    for _, row in df_purchases_part1.iterrows():\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO facts_purchase (id_inventario, id_store, id_brand, id_vendor_number, \n",
    "                                             id_po_number, receiving_date, purchase_price, quantity_purchases)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", row['id_inventario'], row['id_store'], row['id_brand'], row['id_vendor_number'], \n",
    "           row['id_po_number'], row['receiving_date'], row['purchase_price'], row['quantity_purchases'])\n",
    "\n",
    "    # Confirmar la inserci√≥n de datos\n",
    "    conn.commit()\n",
    "    print(\"Datos insertados correctamente en 'facts_purchase' en Cloud SQL.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al insertar datos en 'facts_purchase': {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
